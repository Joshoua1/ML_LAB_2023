{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reinforcement Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "\n",
    "    def make_move(self, row, col):\n",
    "        if self.board[row][col] == 0:\n",
    "            self.board[row][col] = self.current_player\n",
    "            self.current_player = 3 - self.current_player  # Toggle between players\n",
    "\n",
    "    def is_game_over(self):\n",
    "        # Check rows, columns, and diagonals for a win\n",
    "        for i in range(3):\n",
    "            if self.board[i][0] == self.board[i][1] == self.board[i][2] != 0:\n",
    "                return True\n",
    "            if self.board[0][i] == self.board[1][i] == self.board[2][i] != 0:\n",
    "                return True\n",
    "        if self.board[0][0] == self.board[1][1] == self.board[2][2] != 0:\n",
    "            return True\n",
    "        if self.board[0][2] == self.board[1][1] == self.board[2][0] != 0:\n",
    "            return True\n",
    "        # Check for a draw\n",
    "        if np.all(self.board != 0):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_valid_move(self, row, col):\n",
    "        return 0 <= row < 3 and 0 <= col < 3 and self.board[row][col] == 0\n",
    "\n",
    "    def print_board(self):\n",
    "        for row in self.board:\n",
    "            print(\" \".join(map(str, row)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current board:\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current board:\n",
      "0 0 0\n",
      "0 2 1\n",
      "0 0 1\n",
      "Current board:\n",
      "1 2 0\n",
      "0 2 1\n",
      "0 0 1\n",
      "Invalid move. Try again.\n",
      "Current board:\n",
      "1 2 0\n",
      "0 2 1\n",
      "0 0 1\n",
      "Invalid move. Try again.\n",
      "Current board:\n",
      "1 2 0\n",
      "0 2 1\n",
      "0 0 1\n",
      "Invalid move. Try again.\n",
      "Current board:\n",
      "1 2 0\n",
      "0 2 1\n",
      "0 0 1\n",
      "Invalid move. Try again.\n",
      "Current board:\n",
      "1 2 0\n",
      "0 2 1\n",
      "0 0 1\n",
      "Current board:\n",
      "1 0 0\n",
      "0 0 0\n",
      "0 0 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\ML_Lab_2023\\Reinforcement Learning\\Reinforcement Learning.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     play_game()\n",
      "\u001b[1;32me:\\ML_Lab_2023\\Reinforcement Learning\\Reinforcement Learning.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCurrent board:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m game\u001b[39m.\u001b[39mprint_board()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m row, col \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mint\u001b[39m, \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter your move (row and column): \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit())\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m game\u001b[39m.\u001b[39mis_valid_move(row, col):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ML_Lab_2023/Reinforcement%20Learning/Reinforcement%20Learning.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     game\u001b[39m.\u001b[39mmake_move(row, col)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, epsilon=0.1, alpha=0.2, gamma=0.9):\n",
    "        self.q_table = {}\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((state, action), 0.0)\n",
    "\n",
    "    def choose_action(self, state, valid_moves):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(valid_moves)\n",
    "        else:\n",
    "            best_actions = []\n",
    "            best_q_value = float(\"-inf\")\n",
    "            for action in valid_moves:\n",
    "                q_value = self.get_q_value(state, action)\n",
    "                if q_value > best_q_value:\n",
    "                    best_actions = [action]\n",
    "                    best_q_value = q_value\n",
    "                elif q_value == best_q_value:\n",
    "                    best_actions.append(action)\n",
    "            return random.choice(best_actions)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        old_q_value = self.get_q_value(state, action)\n",
    "        next_max_q_value = max(\n",
    "            [self.get_q_value(next_state, next_action) for next_action in [(i, j) for i in range(3) for j in range(3)]]\n",
    "        )\n",
    "        new_q_value = (1 - self.alpha) * old_q_value + self.alpha * (reward + self.gamma * next_max_q_value)\n",
    "        self.q_table[(state, action)] = new_q_value\n",
    "\n",
    "\n",
    "def get_reward(game, player):\n",
    "    if game.is_game_over():\n",
    "        if np.any(game.board == 3 - player):\n",
    "            return -1  # Opponent wins\n",
    "        elif np.any(game.board == player):\n",
    "            return 1  # Player wins\n",
    "        else:\n",
    "            return 0  # Draw\n",
    "    return 0  # Game ongoing\n",
    "\n",
    "\n",
    "def play_game():\n",
    "    game = TicTacToe()\n",
    "    agent = QLearningAgent()\n",
    "    player = 1\n",
    "\n",
    "    num_episodes = 10000\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        game.reset()\n",
    "        state = str(game.board.flatten())\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if player == 1:\n",
    "                valid_moves = [(i, j) for i in range(3) for j in range(3) if game.is_valid_move(i, j)]\n",
    "                action = agent.choose_action(state, valid_moves)\n",
    "                game.make_move(action[0], action[1])\n",
    "                next_state = str(game.board.flatten())\n",
    "                reward = get_reward(game, player)\n",
    "                agent.learn(state, action, reward, next_state)\n",
    "                state = next_state\n",
    "                player = 3 - player\n",
    "            else:\n",
    "                print(\"Current board:\")\n",
    "                game.print_board()\n",
    "                row, col = map(int, input(\"Enter your move (row and column): \").split())\n",
    "                if game.is_valid_move(row, col):\n",
    "                    game.make_move(row, col)\n",
    "                    player = 3 - player\n",
    "                else:\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "\n",
    "            done = game.is_game_over()\n",
    "\n",
    "        reward = get_reward(game, player)\n",
    "        agent.learn(state, action, reward, None)\n",
    "\n",
    "    print(\"Training complete. You can now play against the trained agent.\")\n",
    "\n",
    "    while True:\n",
    "        game.reset()\n",
    "        player = 1\n",
    "        state = str(game.board.flatten())\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if player == 1:\n",
    "                valid_moves = [(i, j) for i in range(3) for j in range(3) if game.is_valid_move(i, j)]\n",
    "                action = agent.choose_action(state, valid_moves)\n",
    "                game.make_move(action[0], action[1])\n",
    "                state = str(game.board.flatten())\n",
    "                player = 3 - player\n",
    "            else:\n",
    "                print(\"Current board:\")\n",
    "                game.print_board()\n",
    "                row, col = map(int, input(\"Enter your move (row and column): \").split())\n",
    "                if game.is_valid_move(row, col):\n",
    "                    game.make_move(row, col)\n",
    "                    player = 3 - player\n",
    "                else:\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "\n",
    "            done = game.is_game_over()\n",
    "\n",
    "        game.print_board()\n",
    "        reward = get_reward(game, player)\n",
    "\n",
    "        if reward == 1:\n",
    "            print(\"You win!\")\n",
    "        elif reward == -1:\n",
    "            print(\"Agent wins!\")\n",
    "        else:\n",
    "            print(\"It's a draw!\")\n",
    "\n",
    "        play_again = input(\"Play again? (yes/no): \").lower()\n",
    "        if play_again != \"yes\":\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
